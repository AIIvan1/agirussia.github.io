## 12 октября 2023 - AGI: формирование иерархических компонентных взаимодействий со сложным миром — В. Смолин—Семинар AGI)
[![Watch the video](https://img.youtube.com/vi/agGV70bvpFY/hqdefault.jpg)](https://youtu.be/agGV70bvpFY)

А. КОЛОНИН [00:00:05]  : Коллеги, всем добрый вечер. Сегодня у нас в гостях Владимир Смолин и он нам расскажет про AGI, как формирование иерархических компонентных взаимодействий со сложным миром. Владимир, пожалуйста.
В. СМОЛИН [00:00:17]  : Владимир Смолин Спасибо. Ну, я приветствую всех тех, кто пришел в Zoom, может быть, тех, кто смотрит по Ютьюбу. я всегда стараюсь сказать покороче, но тут некоторые всегда компромиссы между тем, что рассказать мало будет непонятно, рассказать много тоже будет непонятно, поэтому я начну с краткой идеи о том, что мы не можем взаимодействовать со сложным миром, как в целом, мы всегда Более того, в этой небольшой части, которую мы воспринимаем, мы выделяем отдельные объекты, которые можно статистически достоверно изучить и понимать их свойства. А даже вот эта малая часть мира, которая нам доступна в ощущениях, она никогда не повторяется. Поэтому вот сложный окружающий нас мир мы статистически изучать не можем. Просто потому, что он каждый раз проявляется по-новому. но вот это вот возможности, во-первых, локальное взаимодействие с большим миром, она, значит, упрощает его понимание и второе, что все-таки мы в нем можем выделять какие-то простые объекты, выявлять статистически достоверные свойства и с ними взаимодействовать, вот в этом смысл названия, что есть некоторые компонентные представления о внешнем мире, ну и вот эти простые объекты мы можем статистически достоверно изучать, А как они взаимно расположатся достоверно мы не можем изучать, потому что они каждый раз по-разному располагаются. Зато мы можем, имея модели этих объектов, представить, какие между ними могут все-таки выявить свойства взаимодействия между этими компонентами и составить такое графическое объекте. свойств простых взаимодействий между простыми объектами, свойств простых взаимодействий между простыми взаимодействиями между простыми объектами, и так значит несколько степеней. Вот такое вот иерархическое описание взаимодействия с внешним миром, если очень коротко сказать о том, что я дальше расскажу более подробно. в целом проблема описания внешнего мира состоит в том, что мы уже очень хорошо научились описывать внешний мир и с помощью нейросети, и без нейросетей, уравнениями, словами очень по-разному, различные рисунки можем составлять, семантические сети составлять и вопрос в том, что нам собственно не хватает для создания сильного искусственного интеллекта он широко дискутируется И вот тут буквально позавчера, собственно, Петр Нурлик. с некоторой статьей, ну и в принципе он говорит достаточно правильные вещи, но и там он указывает, что у многих есть такое представление, что алгоритмы в сознании ни к чему, они и так делают правильные вещи, а сознание это такое что-то человеческое, которое собственно не надо воспроизводить. То есть мы конечно там дышим, у нас бьется сердце, а алгоритм вполне может без этого обходиться. Ну, значит, я не хочу сказать, что я дам какое-то окончательное решение этому вопросу. Я расскажу о своем впечатлении, что вот для взаимодействия с внешним миром некоторые процессы контроля за этим взаимодействием можно сопоставить с сознанием. А можно и не сопоставлять. Это, собственно, вопрос веры каждого. вчерашнюю статью как раз говорит о том, что было бы разумнее отделять интеллект от сознания от чувственности. Но это не значит, что они друг другу не помогают. То есть наличие сознания и чувственности с моей точки зрения, оно собственно должно помогать интеллекту. То есть сердце может быть искусственным интеллектуально агентом не обязательно, а вот сознание и чувственность они в общем были бы ему полицией. Это вот мой такой вопрос. предварительный анонс к тому, что будет дальше. Но обсуждать эти представления на основе того, что у нас там в голове, мы что-то о них представляем, это неправильно. То есть то, что Чалленберг говорит о том, что трудная проблема сознания, если обсуждать от первого лица, она не позволяет. однозначно решить проблему, поскольку каждый в голове у себя думает что-то свое про эти понятия, а передать словами хорошо никто не может. Поэтому их нужно рассматривать не на личных ощущениях каждого, а на некоторые модели, которые может быть сопоставлены с какими-то представлениями из психологии. Ну и естественно я не настаиваю, что тот подход, который предлагаю я, это единственный и правильный, ради бога но я стараюсь изложить какие проблемы есть с математической точки зрения с взаимодействием со сложным миром зачем там нужно собственно разбиение его на простые объекты, чему нужна иерархия, о чем я уже вкратце сказал, ну и какие процессы можно сопоставить с сознанием и прочим психологическим процессом В целом, система познания мира, она, конечно, довольно сложная. С миром нужно взаимодействовать через какие-то физические воздействия. То есть, неважно, в реальном, виртуальном мире, но какое-то тело, которое может воздействовать на остальные части мира, все равно нужно иметь. Значит, если мы хотим оптимизировать свое поведение, нужна система оценок, что у животных соответствует какому-то центру удовольствия, и оно, правда, достаточно комплексное понятие, но, тем не менее, каждое животное но, как я ниже скажу, что все не сводится к скалярной оценке лучше-хуже, там все несколько сложнее, на мой взгляд. Но, тем не менее, основное направление моего рассказа будет посвящено построению архитектурной структуры моделей для описания свойств простых объектов и явлений внешнего мира и взаимодействия. вопросы, их можно отдельно обсуждать, может быть как-нибудь я соберусь это сделать, но сегодня я хочу сконцентрироваться именно на построении графической модели и поскольку я буду говорить о том, что управление нижними объектами идет через постановку цели, то собственно вот эта структура, она необходима для выбора целей управления телом, при помощи системы оценок все это работает, но содержание моего рассказа будет посвящено вот этому блоку, где у нас строится иерархическая структура. Важно при этом понимать, какие я смысл буду вкладывать в данные, информацию и знания. То есть, естественно, сенсоры получают входные какие-то данные, и на эффекторы мы направляем какие-то выходные данные, которые получены путем обработки входных данных и тех знаний, которые у нас есть. В отличие от знаний, я воспринимаю как описание известных нам свойств внешнего мира путем характеристик тех моделей простых объектов и явлений. Естественно, каждый миг нам эти знания не нужны, нам нужны только те знания, которые необходимы в данный момент. И информация, которая извлекается из входящих данных и имеющихся знаний, состоит в том, что какие знания нам необходимо использовать, чтобы преобразовать входные данные в выходные. крыжок, который необходимо использовать прямо сейчас или в ближайшее время, в той ситуации, которая происходит или планируется, эта информация соответствует конкретной ситуации. А знания имеют общий характер, они могут быть примены к различным ситуациям, и они у нас хранятся и используются по мере необходимости возникновения тех ситуаций, которые им более или менее соответствуют. в целом кибернетика это такая наука которая занимается процессами управления в технических и живых системах ну и ее важным успехом является сравнение, строение теории регулирования ну как вы знаете там за счет обратной связи с помощью передаточной функции Организуется такое воздействие на объект управления, которое позволяет достичь цели управления. Как правило, управление самолетом или автомобилем, вы поворачиваете руль или ручку управления самолетом, и некоторым образом, не напрямую, идет взаимодействие на колеса или на управляющую поверхность самолета, это достаточно развитая и успешная наука, но она работает в основном для относительно простых систем. то есть, во-первых, вот эти передаточные функции они линейны в смысле дифференциальных уравнений, которые они описывают, и достижение цели идет динамически, там сейчас основной не основное, а важным достижением является переход в этих управлениях не от механической обратной связи, а к электрической обратной связи, которая значительно быстрее, что уменьшает задержку ТАО, и это дает большую прогресс в улучшении качества управления, но не решает проблему управления сложными системами, там все не так просто. Тем не менее, можно себе представить это управление по цели иерархически. То есть, если в предыдущем слайде у нас цель управления задавалась откуда-то извне, то цель управления может быть задана значительно более общая, и она может конкретизироваться через несколько передаточных функций, Вопрос, как становится самая верхняя цель управления, я сегодня предпочту не обсуждать, хотя то, о чем я рассказываю, предполагает, что и верхняя цель управления тоже может быть создана на основе получения тех знаний об окружающем мире и заложенных в систему функций оценки об окружающего мира, ну, для достижения каких-то соотнесений, скажем так, заложенных в систему оценок и свойства окружающего мира, то есть не только под целью можно выбирать, но и самую верхнюю цель можно выбирать. Но я сегодня не хочу на этом останавливаться, поскольку это нас ведет в достаточно далекие истории, но, значит, по крайней мере, хотел бы до вас донести, что с моей точки зрения такая возможность есть, выбрать не только локальный, но и глобальный цель. Вот, ну и, собственно, для построения сильного искусственного можно выделить там ряд целей, то есть все, опять-таки, на мой взгляд присвоится не только к оптимизации преобразований входных данных и выходных, но и какие-то более глубокие алгоритмы оптимизации, то есть декомпозиция, локализация, линеризация и, собственно, получение новых знаний. И концептуально это решает, на мой взгляд, такие вещи, как проблемы сложности мира, причем не только декомпозиция, но и линеризация и локализация тоже решают эту проблему. явном виде локализации это тоже важно и собственно работает на решение проблем сложного мира, как я уже сказал, ну и если мы хотим строить непрерывное управление в нашем, скажем так, термодинамически воспринимаемом мире, поскольку мы вот эти молекулярно-квантовые эффекты не воспринимаем своими органами чувств, то мир мы воспринимаем как термодинамическое приближение, и там наше восприятие этого мира идет как непрерывно. Хотя мы как раз-то научились его описывать не только значит квантовые свойства, но и на цифровой технике дискретно описывать этот непрерывный мир с помощью цифровых приближений. тем не менее, построение непрерывного управления, пусть дискретными цифровыми приближениями, оно возможно, и лионеризация этого процесса, она значительно упрощает процесс этого построения. Ну и как я уже говорил, что важнейшим в этом процессе аспектом является построение целей управления. и оптимизация путей достижения, что можно достигать за счет получения новых знаний, ну о чем, собственно, важная часть моего доклада. Ну и что еще важно отметить, я выделил крупным текстом, что… Идет не просто оптимизация какой-то отдельной модели, а идет на самом деле развитие как животного мира, так и цивилизации, отдельных форм и прочее. И везде присутствует конкуренция. То есть вообще всякое развитие, оно связано с наличием конкуренции. Если конкуренции нет, то, как правило, и развитие идет очень медленно, если вообще нет. И важно не только более оптимальное решение находить, но важно находить их быстро. будем искать очень хорошее решение сто лет, то за это время нас конкуренты много раз съедят и от пользы от нашего решения не будет никакого. Ну сейчас, как вы знаете, искусственный интеллект у всех почти что сходится к мысли, что надо все-таки строить на нейронных сетях, а нейронные сети, они осуществляют аппроксимацию преобразования входных данных в выходные, продвинутыми и позволяют решать очень много задач, которые, несмотря на мрачный прогноз, что всякая задача, которая решена машиной, она перестает быть интеллектуальной. вот уже 10 лет задачи, которые успешно решаются на РСТМе, они как-то сохраняют свою интеллектуальность, несмотря на то, что достаточно успешно решены. тем не менее, проблема многомерной аппроксимации она состоит в том, что если у нас, скажем так, управление зависит только от одного параметра, то эту зависимость легко выйдет. ну, тут я, правда, упрощенно для статического случая даю. там для фазового портрета, конечно, там будет 2 переменных, не только сама величина, но и ее производная, но все равно двумерное, как бы, свойство фазового портрета всего из одной компонент состоит, там плоскость получается, некоторые генетические свойства системы легко выявляются но если размерность растет, то сложность выявления зависимости между компонентами и тем управлением и даже одной компонентом управления компонент если много там тоже сложность задач повышается ну с ростом размерности понятное дело растет и вот если в это значит рост размерности дается выявить какие-то дополнительные переменные которые сводят задачу более низкоразмерно это сильно облегчает задачу ну и в целом еще проблема состоит в том, что чем выше размерность, тем больше расстояние между теми точками, в которых мы побывали то есть если у нас, допустим, вот это вот двумерный случай, и вроде вот кривые более-менее замели некоторую область представления сигнала тут как бы смотрится, что даже чаще эти кривые расположены но если мы себе представим, что это все-таки трехмерный случай, как тут нарисовано, что есть вот третья компонента интересно, видно мою мышку или не видно? я не слышу. кто-нибудь ответите.
А. КОЛОНИН [00:17:18]  : видно? видно. с хвоста просто. стрелочку видно.
В. СМОЛИН [00:17:23]  : компоненты и, соответственно, вот тут некоторый штришок нарисован, что имеется в виду, что это трехмерный случай. ну и если вот в двумерном случае понятно, что кривые пересекались, есть точки, где там побывали не один, а как минимум то в трехмерном уже случае понятное дело, что не то, что совсем эти кривые отслеживающие изменения в состоянии нашей системы не могут пересечься, но скорее всего этого вообще никогда не произойдет. ну и собственно с ростом размерности, то есть вот допустим если у нас нарисуем куб, там четырехмерный куб, пятимерный куб, размер диагонали в кубе, он растет достаточно по простой формуле, что это просто корень n, где n размер, естественно, стороны нашего куба равны единице. ну и понятно, что с ростом n, диагональ нашего n-мерного куба, она стремится так же, как n, к бесконечности. ну правда, не так быстро, по корну, но, понимаете, корень n тоже бесконечно растет. и это приводит к тому, что если мы в каждый из кубов помещаем одинаковое число точек, то расстояние между точками заметно увеличивается. А чтобы сохранять примерно такое же расстояние между точками, как было, допустим, в кубе, нужно экспоненциально увеличивать число этих точек, что, как вы понимаете, очень быстро приводит к таким числам, когда мы не можем продолжать такое увеличение, просто потому что вычислительные возможности у нас кончились. Ну и говорить о том, что вот есть закон Мура, который нас всех спасет, Ну, это, в общем, некоторое преувеличение, тем более, что даже если техниологический причин, он не закончится, там у нас уже примерно 5% потребляемой человечественной энергии идет на вычисление, ну и, соответственно, в 25 раз мы сейчас можем увеличить. общий объем вычислений, который выполняется человечеством, на вся энергия пойдет на эти вычисления. конечно будущее поколение вычислительной техники будут более экономичные, они будут потреблять меньше энергии на одну бинарную операцию, но… экспоненциальный рост вот так вот за счет законного уровня никогда не будет достать преодолено, потому что мир сложный и в нем очень много проблем. дело не в том, что проблема, много компонентов и вот их суммарная активность, возможность различных вариантов она слишком большая. Ну и лучше даже говорить, всё то, о чём я дальше буду рассказывать, лучше соотносить с виртуальным миром или даже с настольными играми. Почему? Потому что про реальный мир мы всегда в некотором сомнении. Что-то мы про него знаем, а что-то не знаем. А если посмотреть на виртуальный мир, там всё просто, там можно познакомиться с его творцом, там либо это Вася, либо какой-то коллектив разработчиков. и они могут рассказать про этот виртуальный мир и там все. Знаем ли мы теперь после этого все свойства этого мира? Ну, вот мое, собственно, утверждение, что нет. Несмотря на то, что, допустим, как в шахматах, мы там можем научить ребенка играть в шахматы, ну, кто-то за 15 минут, считай, может научить, кто-то за 10, кто-то за полчаса, но если там ребенок больше 6 лет, то особых проблем не возникнет. вот, но чтобы он стал ну хотя бы там перворазрядником ему придется много лет учиться, а чтобы гроссмейстер нужно еще чтобы у него были хорошие данные для этого. тогда собственно через 10-15 может быть он станет гроссмейстером. вот, аналогичная ситуация ну грубо говоря со всеми сложными мирами. от того что мы знаем все их простые свойства, мы больше бы других свойств не вкладывали как в шахматы. все достаточно просто. это не значит, что мы теперь знаем, как действовать в этом мире. т.е. там можно находить какие-то новые явления, то, что там синергетики называются, синергия, эмержентность и прочие радости, и, соответственно, построение своего взаимодействия будет сложным даже в простых настольных играх, типа шахмат, тем более го. то есть, если в крестике нолики, которые 3 на 3, мы можем набрать 6045 позиций, что с первого взгляда кажется как же так, там всего может быть либо крестик, либо нолик. в девятой степени будет всего 512, но в одну и ту же позицию можно пройти с разной последовательностью ходов. и вот такие различные позиции получаются. тем не менее, как понимаешь, 6000 позиций при упорном труде за день-два можно все рассмотреть и получить полное знание про эту простую игру. значит с шахматами так уже не удастся. но из бо тем более так не удастся. ну как вы знаете, шахматы нам научились играть и без нарисовки, и диплоу обыграл Каспарова, и в бо альфа-зеро прекрасно играет. но важно отметить, что когда игровое поле увеличивается с 9 до 64 клеток, то сложность полного перебора возрастает на 43 порядка. и, соответственно, если еще увеличить поле от 64 до 361 клеток, то еще единичку и 124 но вот конечно никто и только сейчас но и собственно ближайшие сотни лет такой переборник если вот закон мура не прекратится то где-то лет через 700 800 либо позволит перебрать все возможные состояния. но это значит простой настольной игре, где всего 361 поле. в реальном мире или даже в виртуальном мире, который немножко посложнее, чем игроков, там никаких полного перебора никогда не будет. ну и заканчивая введения, и наконец переходя к содержательной части, хочу вспомнить, что вот в этом же году, в июне 23-го года, вот тут есть ссылочка, значит, рассказа, как, значит, Хинтон, о чем он рассказывал, ну, краткая выжимка состоит в том, что вот мы уже почти создали искусственный интеллект, и это какая-то опасность для человечества, и, собственно, Норвег сегодня, позавчера выступил со статьей, которая тоже говорит, что, в принципе, вот эти вот базовые модели фаундэшнл моделс, они как бы уже есть искусственный интеллект, то есть сильный искусственный интеллект. потом мы будем говорить, то есть так же как мы сейчас говорим про исходные модели, исходные компьютеры середины прошлого века, что это уже были компьютеры, точно так же мы и про эти модели в дальнейшем будем говорить, что это сильный искусственный интеллект, хотя он… конечно еще будет усовершенствоваться, так же как и компьютеры за последние семьдесят лет очень сильно усовершенствуются. но я не соглашусь с Хинтоном, он, конечно, отец. вот он рассказывает, что в базовых моделях сейчас в сто раз меньше параметров, чем у нас в без софт-связи между нейронами, а тем не менее они уже работают почти что как человек. ну, на его совести, насколько эти модели уже работают почти что как человек, но они не решают важную задачу, что они не настроены на получение новых знаний из реального мира. То есть в основном эти базовые модели, и это, конечно, небольшое достижение, они используют знания, полученные человеком и накопленные в тех текстах, которые используются там. в больших языковых моделях и, что интересно, эти же знания в больших языковых моделях позволяют не только работать лучше с текстами, но и лучше распознавать изображения, лучше их генерировать, соответственно, генерировать какие-то звуки, в том числе музыку писать, ну и, собственно, вот этот... Разбиение мира сделано человеком, который писал тексты. Ну, там не один я писал «Всё человечество». Вот анализ этого разбиения мира на компоненты, он сильно помогает современным базовым моделям. Вот. Ну и, собственно, о чём я дальше буду говорить, что важно, и то, чего не хватает для сильного искусственного выделять из мира простые объекты и явления. то есть я не считаю, что современные нейросети этого не делают. они это делают в той или иной форме, но беда в том, что это не является их центральной задачей. это у них побочный эффект, который позволяет им эффективно работать. но непосредственно сами модели, так явной формы, они не направлены именно на разделение мира на компоненты. А с моей точки зрения это важная часть сильного искусственного интеллекта, о чем я попытаюсь в дальнейшем до вас довести. И давайте перейдем, наконец, к основным идеям, которые я хотел сегодня рассказать. Это у меня будет где-то 15 слайдов на эту тему. В принципе, можно рассматривать все современные нейронные сети как табличные аппроксиматоры, то есть то, что... Каждая нейронная сеть осуществляет некоторую аппроксимацию преобразования входного сигнала выходного, с этим многие соглашаются и я с этим полностью согласен. Ну а то, что это как табличный аппроксиматор, поскольку для этого преобразования используется матрица весов связи, то есть таблица, ну тут тоже особых сомнений я не думаю, что у кого-то возникает, хотя у каждого есть право на свое мнение, я никого не хочу в этом абсолютно убеждать. но в целом работа с теми данными, про которые я говорил на основе тех знаний, они состоят в том, что нужна пространство состояния входного сигнала x, выпадает какой-то вектор в состоянии x, и его нужно преобразовать в вектор y. ну и можно, собственно, осуществлять некоторое преобразование, каким путем? что из числа нейронов выбираются те, которые сильнее отвечают на вектор текущий x. и вектором y воспроизводит выходные данные, которые нужны для соответствия этому преобразованию. Ну как там обучаться? Я сейчас не буду останавливаться, все знают прекрасно эти методы. Ну и что важно, что у нас не просто нейросеть, как память. То есть, допустим, активировался один нейрон и вот одну точку это нам не нужно, поскольку память у нас была еще до нейросетей давно, еще на первых вычислительных машинах, и мы могли достаточно много запоминать таких соответствий, а сейчас можем очень много запоминать. важно, что если x совпадает где-то между точками, для которых эти векторы весов соответствуют, то активируются несколько нейронов, там может быть 2, может быть 10, может быть 100, но, короче, свои активации они позволяют некоторую аппроксимацию преобразования входного сигнала x в y, и это преобразование работы. Ну что сейчас работают все эти так называемые независимые активности, то есть может активироваться сколько угодно элементов во внутренних слоях, ну конечно там осуществляется в целом более или менее слабо, но может быть активно хоть все. на мой взгляд надо постепенно переходить к сетям с конкурентной активностью, тогда это преобразование будет более естественно осуществляться, то есть когда мы выделяем несколько элементов ближних, скажем так… пространстве x к той точке, которая нам представлена на вход, то соответственно по ним можно эффективнее во-первых преобразовать, во-вторых быстрее обучать, и когда мы обучаем какой-то элемент локально, то мы не портим все остальное от преобразования, что в целом должно работать на ускорение обучения. Но в принципе то, с чем я рассказываю, это вопрос не принципиальный. То есть можно и на 5-ти или на других сетях реализовать этот компонентный подход, хотя повторюсь, с конкурентной несколько лучше. Ну и перейдем к описанию пространства, состояния, которые мы наблюдаем. То есть, если мы видим кошку, мы знаем, что по-английски она называется cat, и глазом воспринимаем зрительно эту кошку в виде вектора активации сенсоров в глазах. вот и после некоторой предобработки этот вектор приводит к активации там у нас зрительных полей и в коре ну и там много другой активности развивается вот но значит когда этот вектор изменяется то значит как там кошку не поворачивая она там на танк там или на березку похоже не будет вот и соответственно есть некоторое пространство состояний нашим зрительным образом который соответствует кошке ну и если кошка обладает какими-то динамическими свойствами, то может быть фазовый портрет вот этого пространства, то есть не только координаты x, но и x с точкой, то есть производная по времени, они характеризуют это пространство плюс его динамические свойства. вот собственно на основе наблюдений за кошкой можно создать ее динамические свойства. кошка достаточно высокоразмерный объект, поэтому естественно этот процесс лучше осуществлять иерархически, но и самое сложное состоит в том, что эту кошку надо как-то выделить из еще более сложного пространства, в котором она находится, в котором много других объектов, и уж вместе с теми объектами мы, значит, никоими силами вот этот вот пространство состояния никогда не построим модель, поскольку очень редко там будут проходить эти траектории и никогда не повторятся. ну и основной путь к такому стоит декомпозиция, то есть если вот мы видим картинку и вот это нам на картинке знакомо, а допустим ракетку мы увидели впервые, то собственно путем декомпозиции можно выделить изображение на эту ракетку и тогда у нас задача выявлению свойств будет значительно проще, поскольку параметров оптических ракет не так много и есть надежда что мы сможем достаточно быстро построить статистически достоверную модель пространства и состояния, в котором может эта ракетка находиться. Ну, естественно, сравнивать надо не непосредственно изображение, сравнивать надо предобработанное изображение, преобразованные там векторы активности, ну и, собственно, образ ракетки, он тоже получается, вот мне так, что изображение вычитаем изображение. идет какой-то локальный анализ изображения, формируется сколько-то слоев активности, активность места открытых слоев, ну и уже к некоторому слою мы можем выделять образ уже не компонент ракетки изображения, а собственно именно уже ракетку, как новый образ, для которого у нас нет модели. в чем, собственно, польза такого явления, что, ну допустим, вот кошка с ракеткой, хотя, конечно, кошка значительно сложнее, чем ракетка, но, допустим, что у каждого из этих образов, допустим, есть там по миллиону разных состояний, которые необходимы, чтобы статистически достоверно описать их пространство состояния, тем более динамическое. мы не видим, зато кошку видим без ракетки. тогда мы можем построить модель кошки без ракетки и соответственно потом, наблюдая кошку с ракеткой, вычесть из этого вектора суммарного состояния состояние кошки и останется вектор ракетки. состояние вектора ракетки будет значительно меньше, чем суммарного состояния, то есть поскольку кошка и ракетка могут быть практически в произвольном состоянии, то ну там конечно есть зависимость там вряд ли там возьмет зубы или еще как-то более извращен на кошка ракетку но все равно совместных состояний – это практически прямое произведение возможных состояний каждого из пространств. Если, допустим, на изучение кошки нам, допустим, потребовалось сутки миллионы различных состояний посмотреть, то соответственно прямое произведение по миллиону – это будет триллион, то есть в миллион раз больше, и соответственно уже потребуется… скажем так, очень много суток, то есть больше человеческой жизни, чтобы смотреть все их возможные комбинации. В то время как, если мы вычитаем, то примерно за сутки мы те же миллионы состояний ракеты посмотрим и значительно быстрее статистически достоверно построим модель свойств этого агента. что входной сигнал, который мы получаем, наблюдая сложный объект, можно разделить на компоненты. То есть для этого нужно из входного сигнала вычесть воспроизводимые для известного объекта компоненты, и тогда на каждую нейросеть пойдет некоторая часть входного сигнала, это разделение произошло, то соответственно модели каждой компоненты можно достаточно быстро рассуществлять. самое главное, чтобы изначально у нас хотя бы какие-то компоненты были известны. тогда если оставшиеся компоненты достаточно простые, то их легко понять, и мы достаточно быстро построим модель ранее неизвестного объекта. ну а если нам объекты известны, то модель работает устойчиво, соответственно, если в сцене присутствуют одни и те же объекты, которые меняются в состоянии, они разделяются на разные компоненты, и все работает, но естественно компонентов должно быть не два, а значительно больше и естественно когда мы наблюдаем какую-то сцену, мы на ней видим не все те объекты, которые мы вообще знаем, а только некоторые ну и то есть у нас должно быть достаточно много моделей, какие-то из них активируются и с помощью нелинейной декомпозиции выявляется, в смысле осуществляется разделение на компоненты и по взаимодействию с каждой компонентой на основе, о чем я буду говорить дальше, поставленной сверху цели формируются некоторые выходные сигналы и ну, важное тут, собственно, состоит в том, что нужно осуществлять нелинейную композицию то есть если бы была вот эта композиция сложных сигналов линейной, то задача вообще была бы элементарной вот, но сейчас основное достижение нейросети состоит в том, что они научились осуществлять нелинейную композицию. И вот эта вот нелинейная композиция, там можно приводить много разных примеров. Вот, ну вот, собственно, здесь такой достаточно известный пример, когда из вот фотографий в верхнем ряду формируется на основе фотографий в левом ряду, собственно, некоторая нелинейная композиция. То есть, если скрестить вот эти вот два портрета, то вот получится... с этим можно посмотреть, что вот ребенка там с девушкой, но поскольку это ведущий источник, то пол сохраняется ведущего источника, ну а некоторые свойства вот этого объекта, они передаются нелинейной композицией. Есть конечно возможности и непосредственно сетями выделять объекты, но... на мой взгляд, конечно их тоже надо использовать, но это вот не самый прямой путь, поскольку такое выделение непосредственно без использования декомпозиции, то есть чтобы это выделялось, какая-то декомпозиция там очевидно есть, и вот ее результат, но она появляется скажем так, не путем проектирования сети на декомпозицию, а путем ее специальных методик обучения. и декомпозиция появляется там в некотором смысле и в режиме. вот. Ну и имеющееся знание, как я уже сказал, помогает получать новые знания. То есть если мы в сложной ситуации какие-то элементы этой сцены знаем, то мы вычитаем из сцены известные нам легенды. Оставшаяся часть сцены, если оказалась простой, то мы достаточно для этой простой части сцены строим ее описание, ее пространство состояние и получаем новые знания про новые компоненты. если мы узнаем малый компонент сложной сцены, то она остается непонятной и мы там ничего, к сожалению, построить не можем. но зато если у нас знание есть, то мы можем говорить о том, что мы устойчиво воспринимаем сцену по простому признаку, что если что-то в ситуации меняется, а те компоненты, которые активировались, наблюдая этот сложный сигнал, номера компонент и их активность если вот вектор активности некоторое время не меняется значит мы устойчиво распознаем какие там простые объекты эту сцену составляют это создает условия для обучения если там оставшийся компонент достаточно простой если же у нас вот это вот картинка активности часто меняется это говорит о том что мы не понимаем как разделять эту сцену ну и ну и, собственно, есть пороговые переходы, то есть если существует повышение качества аппроксимации компонент, тогда, собственно, возникает состояние активности постоянное, и тогда в более сложных сценах может идти устойчивый процесс обучения, когда для остальных компонент сохраняется вектор активации компонента. И обучаться вот этим компонентам нужно не так, что мы увидели одну кошку, обучили одну нейросеть на кошку, но, конечно, повторюсь, это некоторая орфическая структура на каждую кошку, но их должно быть несколько, то есть мало того, что мы должны быть готовы… такой ситуации, что мы встретим не одну кошку, а две, три, четыре, а может быть и пять кошек, и если у нас обучено на кошек несколько нейросетей, то мы сможем в сложной сцене выделить необходимое количество нейросетей на разделение вот этой ситуации на компоненты. апельсины или что-то еще, но короче там один апельсин это апельсин, два апельсина тоже апельсин, а вот сколько апельсина, чтобы было куча, вот собственно когда у нас кончаются эти модели для описания однотипных объектов, у нас начинается куча, поскольку уже мы не можем выделять новые объекты под модели, которые… под объекты этого класса. всем известный пример, что ребенок там запоминает слона с первой картинки, то есть показали ему не то что фотографию слона, а какую-то там детскому книжке нарисована слона, и потом он пойдет в зоопарк и узнает, что да, это слон, то есть это не значит, что он увидев одну картинку, создал совершенно новую модель, то есть он, поскольку это различная структура, были какие-то модели различных животных, он какую-то модель немножко модифицировал, добавив к ней ховоды, большие уши и ноги, как у бегемота, если он, конечно, раньше видел бегемот, что с ним не обязательно. И, соответственно, сформировалась у него некоторая модель слова, которую он дальше легко будет как на картинках, так и в жизни узнавать. Ну и психологи очень любят рассказать, что мы можем воспринимать от 5 до 9 объектов, а в среднем 7 объектов. ну конечно там про внимание моделирования может быть они в чем-то правы, но в целом есть и другие примеры, что даже гроссмейстеры они могут вслепую играть на многих досках. сильные гроссмейстеры могут вслепую играть на 50 досках. ну и там у перворазрядников у всех выиграть. при этом, то есть если вы занимаетесь какой-то деятельностью и треки немного, то вот этих моделей, этих ситуаций у вас в голове достаточно много и вы можете с ними работать. как отдельную личность. в то время как тот кто не занимается категорической деятельностью, ему очень сложно работать с большим количеством. ну и нужно во первых заранее иметь в системе большое количество компонентов сконструированных под моделирование различных объектов. но это большое количество компонентов учится не То есть, сперва мы мало объектов познаем, но обучаются почти все компоненты к копиям тех явлений и объектов, которые мы наблюдаем. А потом идет более мелкая дифференциация на более разнообразные объекты, ну и ресурсы распределяются в зависимости от характера нашей деятельности. Чем мы занимаемся, там у нас больше моделей, а чем мы не занимаемся, там меньше моделей. то важно, что есть некоторое иерархическое представление переменных ну вот я не знаю, насколько это будет понятным может надо немножко напрячься но если вы откроете карты яндекса, то кроме того, что есть собственно карта можно на ней нарисовать маршрут вот тут нарисовано как я бы если бы на машине ехал на работу то вот был бы некоторый маршрут и соответственно вот я бы там выехал из дома поехал там по улице космонавтов там вот Тобелиск в Москве этих космонавтов ну и там постепенно попал бы на работу вот собственно здание из которого я сейчас вещаю институт прикладной математики картинки конечно не соответствуют году но в целом они преобразуют те координаты, которые есть на карте, в тот вид, который мы, собственно, увидим, если будем смотреть в каком-то направлении в этой точке ну и это можно себе представить, что вот в разных областях карты у нас активируются различные нейроны, и поскольку они обучались каким-то входным данным, что можно увидеть в этом месте, автоэнкодеры, которые по своей активации воспроизводят то, что будет. причем не обязательно на вход давать какой-то входной сигнал, можно просто активировать этот нейрон просто по тем координатам, которые там отдельным входом еще... все равно картинка воспроизведется. ну вот я попытался это изобразить, что если распределить в разных точках этой карты можно обсумировать различные нейроны. ну конечно, чтобы там было еще направление, и не только по горизонтали, но и по вертикали, ну там еще как бы дверозмерности надо добавить, но тем не менее, это позволит отображать те картинки, которые мы бы увидели в разных точках этой карты. ну конечно яндекс там мне внутри знаний картинки не показывал, только по дорогам ездит, но в принципе можно себе представить и таковые. ну и естественно может быть не только два уровня, то есть на картах там например можно отражать более общие параметры какие допустим как загруженность дорог, там еще какие-то параметры, ну и их может быть там 2, 3, 4, 5 уровней общности выявления карты, то есть там на разном масштабе может быть различные параметры, разные свойства и эти все параметры они могут быть организованы некоторой расической структурой вот, ну и вопрос как эти уровни взаимодействуют то есть если мы хотим получить какое-то изображение какой-то точки значит нужно выдать координаты этой точки и соответственно нейросеть которая соответствует изображениям выберет тот нейрон который соответствует данным координатам и на выход даст изображение в том направлении опять же которое задано следующего ну и если мы будем просто анализировать изображения по их соседству, то можно, собственно, чисто из изображений создать карту вот этих координат, то есть, наблюдая за изменениями вот тех активностей, которые происходят в сети, тоже можно, собственно, создать карту пространства, состояния и, собственно, ее следовать тут я не хочу уходить в вопросы динамики соответствия но соответственно и когда дается цель то необязательно на выход давать изображение как в случае карты как правило нужно формировать некоторое управление хотя собственно сравнивать то что мы в этой координате видим с тем что мы хотели увидеть это тоже важно вот но Когда задаётся цель, то нужно следить за тем, насколько хорошо она выполняется, и если она либо выполнена, либо выполняется она плохо, то верхний уровень должен как-то на это отреагировать и создать следующую цель. И тут что важно, что цель можно менять непрерывно, если нижние уровни не знают, как достигать целей, которые сильно отличаются от текущего состояния. тогда если может только небольшие изменения делать по управлению, если цель не сильно отличается от текущего состояния, тогда нужно постоянно менять эти цели и чтобы она достигалась. если же сеть там хорошо научена достигать достаточно далеко стоящие цели, то на выполнение цели у нее ну и собственно дело даже не в том, что жалко их простой, а в том, что, как я говорил, для многомерных объектов, то есть сложных ситуаций наша аппроксимация напрямую будет всегда плохой, а если мы сможем промоделировать различные варианты воздействия в той ситуации, которая возникла в первый и последний раз, то есть мы не можем в этой ситуации действовать на основе опыта предыдущих действий но хорошо бы промоделироваться, и этим мы могли бы, промоделировав несколько разных вариантов, выбрать лучший вариант действий и цель, верхний уровень ставит только цель для нижних уровней, то есть поставить наилучшую цель для того, чтобы встроить какие-то рациональные действия соответствующие нашим рекордам. в случае живых систем центр удовольствия, а в случае искусственных систем некоторый аналогичный центр удовольствия – система оценки. И вот это время, которое свободно от воздействия на… в смысле от постановки новых целей, поскольку хорошо справляется нижний уровень достижения цели, моделирование различных вариантов действий и выбор лучших целей для продолжения деятельности. Я надеюсь, сейчас все сидят на стульях или в креслах, как я, и никто не падает. Все равно для этого какие-то наши мышечные активности или пассивности необходимы, чтобы тоже некоторые действия… степень высокости каждый по-разному себе представляет, вот и это вот то что задача не упасть со стула для нас простая и мы с ней там мужичок, спинной мозг прекрасно справляется, собственно головной мозг наш в корах, она в основном свободна для выбора каких-то новых целей, мыслей там о чем-то отвлеченном и вот этот процесс он важен для собственно строения рационального ну и как я говорил, что строить мы можем модели, скажем так, простых действий и с простыми объектами но простые объекты не обязательно должны быть строго локальны, они могут быть как раз протяженными но тем не менее, пусть по каким-то свойствам они некоторые локальности обладают и в целом они не характеризуют ситуацию в целом но мы можем моделировать. Только все-таки простые объекты и явления. Мы можем моделировать также и взаимодействие между этими простыми объектами и явлениями, между ними тоже взаимодействие можно моделировать. И так может быть несколько уровней такого взаимодействия. Ну и, собственно, на верхнем уровне, который обязательно есть, поскольку никакая система не бывает бесконечной, мы все-таки моделируем какие-то достаточно общие взаимодействия. она позволяет, основываясь на простых моделях, формировать представление о какой-то текущей или гипотетически возможной ситуации, ну или непосредственно, если какая-то сложная задача, поиспользоваться для формирования текущих целей, либо если нижние уровни, там несколько один-два-три, хорошо справляются с выполнением поставленной верхней уровней задач, то, собственно, верхние уровни свободны для осуществления моделирования. деятельности, для улучшения аппоксимации целей в той ситуации, которая ожидается. Ну и заканчивая блок основных идей, которые я хотел вынести, хочу рассказать, как с моей точки зрения построен сильный искусственный интеллект. суммирование того, о чем я рассказывал, то есть, как я уже говорил, нужно взаимодействовать со сложным миром, то есть если мы решаем задачу, выберем 5-0 или кинополе 3х3, то в общем это не сильный искусственный интеллект. И собственно шахматы и ГО, мы конечно считаем эти задачи интеллектуальными, но и вот сильный искусственный интеллект мы его не признаем. это связано с тем, что эти задачи, то есть эти системы решают те задачи, которые им поставил человек, а сами собственно эти задачи себе не вырабатывают. Сильный искусственный антикеплет в первую очередь должен получать новые знания о внешнем мире не только от человека, что тоже необходимо и положительно, поскольку уже готовы, собственно. выявленные из сложного мира знания от кого-то получить проще, чем выделить самому, но главное, чтобы такой жесткой зависимости от человека усиливается искусственный интеллект, и вы должны сам уметь выделять новые знания из сложного мира. Вот. неважно как он получил эти новые знания от человека или сам выделил из внешнего мира, но важно на основе этих новых знаний он должен формировать новые цели. Второе – это необходимо, чтобы между уровнями предоставления целей было взаимодействие, то есть верхние уровни ставили нижними некоторые цели, которые те стремились как бы нужна постановка целей, но отслеживание процесса достижения этих целей, то есть насколько успешно идёт процесс достижения поставленных целей. Если всё хорошо, то верхний уровень свободный для моделирования, а если всё плохо, то надо забывать думать о высоком и решать текущие проблемы и ставить новые цели, поскольку старая цель уже понятно, что достигнута не будет на основе тех знаний, которые есть на нижнем уровне. построить противорациональное поведение, нужно выдвигать новые цели. Третий важный пункт – это то, что существует два основных режима выбора цели. Первый – это на основе аппроксимации, то есть непосредственно по входной информации, пока попавший на каждый элемент она выдает выбор, который заложен в том преобразовании, которое она реализует, которое сформировалось путем увлечения с каким-то компонентом, с сложным сигналом. а выделение компонента идет постоянно в системе при взаимодействии со сложными сигналами. иногда успешно, иногда менее успешно. то есть когда успешно, там вроде бы идет понимание того, что происходит, если выделение компонентов не успешно, ну соответственно понимание мягко говоря, становится значительно хуже, а может и отсутствует полоса. Но и если свободное непосредственное движение текущих целей более высокий уровень, то у них есть возможность работать в другом режиме, не на формирование мгновенной цели прямо сейчас, а на моделирование различных вариантов действий в той ситуации, которая раньше мы можем промоделировать, как лучше в этой ситуации действовать, и таким путем, собственно, если продвинуться, выбрать лучшую цель для той ситуации, для которой мы раньше, скажем так, не встречались, и если мы сразу путем аппроксимации выберем цель, то такая цель вряд ли будет самой хорошей. Иногда будет, но не всегда, и лучше проверить, насколько путем непосредственной аплоксимации цен. Четвертое, это если мы хотим моделировать взаимодействие, то нам нужны не статические модели объектов, а их динамические фазовые портреты. Тогда эти фазовые портреты отражают не только статические, но и динамические свойства объектов и их взаимодействий. и собственно можно на основе взаимодействия моделировать развитие той ситуации, которая сложилась или которая мы ожидаем, что сложится и таким путем выбирать более хорошую цель. Для всего этого, как я уже сказал, необходима нелинейная ассуммация, которая моделирует нелинейность восприятия окружающего мира и собственно нелинейность самого мира. Ну и чтобы строить новые цели, необходимы процессы познания, которые я частично затрагиваю, но особенно я не хочу сегодня на них восстанавливаться. Это как бы должна быть тема отдельного доклада. Вот на этом как бы в основном, что я хотел рассказать про основные идеи заканчивается, ну и немножко слайдов обсуждения вот этой модели. то есть в принципе моделей обработки, нейросетевой обработки данных существует очень много вот слева самая видимо известная в наших кругах гиперсетевая теория Внука Анохина но я как говорил, что я видимо не совсем правильно ее понимаю поскольку хотя вот этих простых компонентов их много но вот комбинации этих простых компонент их значительно больше. ну конечно там существует такой взгляд, что реальную эту жизнь мы все-таки проживаем только одну, и вот эта пирамида может отражать то, что наш как бы жизненный путь он единственный. но я все-таки больше склоняюсь к тому, что есть у нас модели для различных ситуаций и различные комбинации мы можем попадать, которые для нас неожиданны, и все-таки находить какие-то там решения. современные сверточно-рекуррентные нерестевые модели в основном работают на проход сигнала насквозь и достаточно эффективно обрабатывают. но хотя в альфа-зеро реализован путь моделирования последствий различных действий, и это очень помогает этой модели, большинство современных моделей этот подход не используют. То, о чем я рассказывал про компонентную структуру, она состоит в том, что не обязательно проводить информацию, данные через всю структуру сети, и, собственно, поиск информации как-то его преобразовывать. А, соответственно, преобразовывать данные, выходные, можно на нижних уровнях сети, когда мы решаем простые задачи, а нижние уровни хорошо... приспособлены, подготовлены для решения вот этих преобразований. А верхние уровни позволяют ставить правильные цели с учетом более сложных ситуаций. Ну и пока, значит, эти цели успешно выполняются, верхние уровни свободны для осуществления каких-либо решений. Ну или в основном этот процесс моделирования тоже можно рассматривать как познание свойств окружающего мира, то есть какие действия лучше в сложившейся ситуации будут на основе имеющихся в окружающем мире знаний и анализа того, как будет развиваться ситуация при различных последовательностях действий, ну и не только последовательности, но и просто при различных действиях ну естественно у биологов тоже есть разные модели, вопрос там павловская модель она не потеряла своей актуальности хотя конечно, собственно прогрессивная она была там стосточным лет назад вот когда вообще не было представления как там нервная система может что-то делать вот те представления которые излагал павлов они конечно замечательные но они не отвечают ряд вопросов на построение То есть как там пища преобразуется, вид пищи преобразуется в выделение слюны, все было бы хорошо, если бы мы понимали как там активируются центры соответствующей пищи в головном мозге и как они связываются с центрами выделения слюны. То есть это все достаточно гипотетическая схема. на каких принципах все это организуется в системе, ну в общем, Павловский подход не затратен. Значит более системный подход, конечно, был у Петра Кузнеча Анохина. Вот и все вот хорошо знают эту схему, там акценты результата действий, там программы действий, но опять-таки как, собственно, знания попадают в память, откуда берется мотивация. как формируется программа действий вот в этой функциональной схеме Анохина все это просто не рассматривается, то есть схема опять-таки для середины прошлого века прогрессивная, но хотя я знаю людей, которые на ее основе сейчас строят сильный искусственный интеллект, но мне всегда было интересно, как у них это получается, поскольку… то есть, конечно, они как-то доработали эту схему, поскольку сам Анухин подчеркивал, что эта функциональная схема она не является структурной, не описывается, как собственно реализовывается. Конечно, каждый может от себя дополнить эту модель какими-то структурными идеями, и все-таки ее развивать нет никаких, с моей стороны, по этому поводу вопросов. Но то, что я рассказывал, состоит в том, что вот этот акцептер результата действия, он, скажем так, многоуровневый, то есть есть много уровней представления знаний, и собственно результаты действия оцениваются на разных уровнях, и выясняется цель какого уровня надо менять. Основное достижение современности – это, конечно, расследование и революция машинного обучения. Имеется там много прекрасных моделей, вот тут краткий список, я даже не буду его зачитывать, может, кто-то может со мной поспорить по поводу того, какие даты правильные, какие не очень, но в целом я надеюсь, что все-таки я какую-то тенденцию отразил. И современные foundation models, конечно, это большой прорыв в пилот и замечательный результат, но о чем я уже говорил, что на мой взгляд все вот эти модели достигли вот этих замечательных результатов в первую очередь за счет того, что они используют произведенные человеком разделение мира на компоненты и отраженные в текстах. То есть в текстах, естественно, каждое слово. простым, и, соответственно, вот эта декомпозиция сложного мира на словесное описание, оно сильно упрощает описание сложного мира. И полезно не только для анализа текстов, но и для генерации картинок, генерации звуков различных, написания музыки и много еще чего. моё отношение к тому, что как бы, как вот, собственно, два дня назад в статье выступил Норвег о том, что вот это уже как бы и есть сильный искусственный интеллект. Ну, я с ним тут не соглашусь, хотя, значит, в принципе, конечно, там достижения у человека были, и можно говорить о том, что сильный искусственный интеллект там произошёл, когда счёты изобрели, или, собственно, когда написали первую книгу, то есть книгам тоже приписывались
А. КОЛОНИН [01:06:38]  : Владимир, что-то со звуком случилось. Так, у вас что-то случилось со звуком. Так. Раз, раз, раз.
В. СМОЛИН [01:07:01]  : Владимир.
А. КОЛОНИН [01:07:16]  : Так, Владимир, попробуйте еще раз.
В. СМОЛИН [01:07:29]  : Вот. Ну и мое, собственно, мнение по поводу того, то есть, скажем так, что в принципе и там какая-то хорошая энциклопедия, она так же, как и современные базовые модели, она позволяет дать очень много различной информации. Другое дело, что базовые модели, они не требуют листания или обращения с запросом как база данных. производят. Но, на мой взгляд, то, что этих моделям не хватает до сильного искусственного интеллекта, это то, что они сами должны уметь выделять из сложного окружающего мира, не обязательно реального или виртуального, любого. на основе анализа изменения векторов, построения пространства в состоянии векторных описаний простых компонентов. и, собственно, вот такое развитие модели. я ожидаю, что в ближайшие годы произойдет. то есть я всегда предназначил, что это будет 25 год. вот уже сейчас говорят про модели, что вот это сильный искусственный интеллект. я с этим согласен, что еще немножко надо их докрутить. но все, на мой взгляд, там выйдет. ну и теперь собственно анализ про некоторые формальные определения, которые можно связать с психологическими, то есть есть представление об интуиции как чем-то таком совершенно сакральном, то есть есть там интуиция, она связана с подсознанием, там еще с чем-то, ну и много идей. я придерживаюсь тех позиций, что все современные мерси сетевые модели, они работают достаточно развита интуиция в том смысле, что интуиция это всегда первая мысль, а преобразование нейросети осуществляют сразу и собственно только альфа-зерона и может быть какие-то связанные другие модели такого типа они осуществляют перед тем как осуществить действие какой-то анализ вариантов продолжения. а большинство нейросетевых моделей работают на интуиции. впрочем альфа-зерона может не осуществлять анализ продолжения, а сразу работать на первом лучшем продолжении которое есть для данной ситуации. но вот в той модели, о которой я рассказывал, то есть есть как бы два режима непосредственно аппроксимации и моделирования, то есть вот как я уже говорил, что абстрактно можно, конечно, про интуицию придумывать что угодно, а если связывать с той моделью, про которую я рассказывал, то, собственно, интуиция она соответствует непосредственно выполнению аппроксимации. все, наверное, сетевые модели аппроксимации не выполняют, ну там с разной степенью и соответственно второй режим он соответствует то есть осуществление моделирования это это это это это это это это это это это это это это это это это это это это это это это это соответствует мышлению, то есть если мы перед тем как выполнить какие-то действия прогоняем в голове различные варианты, ну конечно не любое моделирование соответствует мышлению, значит нужно во-первых, чтобы оно происходило там не в виде физической модели, а в некоторой виртуальной форме, соответственно нужно прогнать как минимум несколько вариантов, ну в принципе даже это не совсем обязательно, если мы прогнали один вариант и поняли, что но в целом есть зачастую возможность и полезно попробовать разные варианты, чтобы сравнивать, какой лучше. и наконец, необходим контроль за тем, какие развития ситуации мы рассматриваем. нужно не только думать о тех действиях, которые выполняем, но и понимать, к чему они идут. процесс моделирования, он должен идти не в произвольном направлении, а контролироваться, насколько он позволяет достичь все цели, которые нам интересны. Ну и вот этот контроль как за выполнением действий не на основе аппроксимации, так и за мышлением, которое связано с моделированием, тоже на основе аппроксимации, но без непосредственной постановки цели нижним должен контролироваться, в том смысле, что когда нижний уровень выполняет действия на основе аппроксимации, если цель достигается успешно, то цель менять не надо. А если становится понятно, что достижение цели не получается, то цель надо менять. И вот тут необходим контроль, и этот контроль, во-первых, логитмически реализуем, ну и, на мой взгляд, это то, что соответствует сознательному контролю. мы либо продолжаем спокойно сидеть слушать, допустим, что я рассказываю, и я тут вам спокойно рассказываю, а если что-нибудь случилось там у вас там за дверью или в комнате хуже того, то естественно... Слушать меня перестали, и я бы перестал рассказывать, если бы тут у нас, не дай бог, что-нибудь взорвалось или загорелось. Но тут все пока спокойно, я рассказываю, и сознательный контроль позволяет мне это делать дальше. Но пора уже заканчивать, я понимаю. Да.
А. КОЛОНИН [01:12:55]  : Но, видите, там у меня... Нет, давайте, давайте, чтобы ничего не взорвалось и не горело. Давайте, давайте.
В. СМОЛИН [01:13:02]  : Поплевал через плечо, надеясь, что не взорвется. Ну и важно, что сознание – это не вообще активность всех нейронов, про которую, конечно, я не буду спорить, что если определить сознание как просто паттерн активности нейронов, которые в голове, оно, конечно, не убиенное определение. Но надо все-таки отделять сознание от других функций высшей нервной деятельности. Ну, что, собственно, и НОР, это тоже своя статья, двухмерные данности предлагает. Вот, то есть сознание, конечно, может и должно использовать результат выполнения других функций высшей нервной деятельности, но это отдельная функция, связанная именно на мой взгляд. И в той модели, про которую я рассказываю, может быть соотнесена именно с контролем за успешностью достижения поставленных целей, ну и успешностью моделирования процессов по достижению поставленных целей. ну, соответственно, сознание должно осуществлять контроль успешности процесса управления, необходимость изменения цели выявлять, то есть если успешность плохая, то надо менять цель. Соответственно, пока цель достигается успешной, верхний уровень не мог быть отключен и использован для моделирования и получения новых знаний для более точного, для более рационального выставления новых целей, ну и, собственно, процесс моделирования тоже он сознательно контролируется, то есть если у нас мысль выходит куда-то совсем не туда, то мы тоже контролируем, что что-то нас занесло не в ту степь. ну и собственно вот это вот в отличие от Анофина, у которого там в модели был собственно один акцент трудействия, то вот в той модели о которой я рассказываю, поскольку несколько уровней и несколько уровней представления, а в обстоятельности представления знаний и модели окружающего мира, то вот эта вот оценка состояния, она уровневая, то есть она скажем так, считается на нескольких уровнях, то есть они конечно могут взаимодействовать, эти оценки, но в целом, значит это вот разделение по уровням, оно может происходить, то есть на области завязанного непосредственного управления и уровня завязанного моделирования, это разделение может проходить на разном уровне, зависит несколько от того, насколько много нужно нижних уровней для выполнения поставленных Ну и понимание, как я уже говорил, связано с тем, насколько мы успешно разделяем сложную сцену на компоненты. успешно разделяем на компоненты, то какое-то понимание есть, но при этом, конечно, уровень понимания может быть разным, то есть понимание правил шахматной игры – это один уровень понимания, собственно, понимание, как там выиграть ребенка – это другой уровень понимания, собственно, понимание то, что, значит, если вы не занимались шахматом, выиграть у перворазрядника даже вы не выиграете, ну, это как бы третий уровень понимания. А если вы понимаете, как выиграть у брасмейстера, ну, соответственно, уровень понимания совершенно другой. Вот, ну и, собственно, вот эти вот да, я понял. 5 минут. и соответственно, уровни понимания конечно могут быть разные, но в любом случае они связаны с тем, что чем лучше мы разделяем ситуацию на компоненты, и чем глубже по уровню, то есть выше по уровню иерархии наша модель хорошо представлена, тем более цельное представление ситуации у нас есть, и тем выше понимание нашей по-первых самой ситуации, ну и в зависимости от того насколько продвинуты у нас модели поведения в этой ситуации, еще есть понимание какие действия будут наиболее рациональны в данной ситуации. Ну, как я уже говорил, озарение, которое, ну, вот, собственно, как и инсайт, и, собственно, и понимание, многие любят циркулизировать, а уж озарение – это вот нечто такое совершенно божественное, которое, как искренне считают многие академики, сходит только на них. Вот там Господь Бог кладет слайм на их чело, и у них там происходит что-то волшебное. В рамках этой модели озарение происходит как совершенно естественный процесс. То есть человек в той области, в которой он активно работает, если ему удается получить новые знания, позволяющие из сложных ситуаций выделить простые объекты, то для таких простых объектов достаточно быстро набирается достоверная статистика. которая позволяет сперва создать непрерывную модель этого объекта в голове, и соответственно ее уже можно описать словесно или формально, и нести до окружающих свое понимание выделенного простого свойства сложных каких-то объектов. Ну и, как я говорил, вот эта вот формула о том, что из общего сигнала мы вычитаем сумму компонентов, чем больше есть компонентов, которые мы знаем, то есть собственно, чтобы прийти к озарению, нужно получить как можно больше знаний в данной области, соответственно, если этих знаний окажется достаточно, чтобы вот эта разность оставила нам небольшой простой сигнал про простой объект, тогда мы про этот простой объект достоверные данные предусмытно, а пока у нас знаний мало и ситуация сложная, то мы, к сожалению, для сложных ситуаций получать достоверную статистику не можем и как бы хотя многие склоняются к тому, что современные инерсити прекрасно с этим справляются, моя точка зрения состоит в том, что они прекрасно с этим справляются, поскольку их структура заточена на то, чтобы быть для сочетания декомпозиции сигналов, которые они обрабатывают. они не явно сконструированы для этой цели, но вот само усложнение структуры, начиная там со свертки, там все возможные гейбс, которые есть и прочие сложности, они направлены все так или иначе в декомпозицию сложных сигналов, которые обрабатываются. про эмоции буквально несколько слов, просто очередно я уже неоднократно про это говорил, что обычно заявляют о том, что смысленное действие основан на скалярной аценте – лучше-хуже, а что еще нужно для системы интеллектуальной задачи – либо она ее хорошо решила, либо она ее плохо решила. Ну и все обутение стоит в том, что она ее лучше решала. Но, значит, при поведении в сложном мире стратегии поведения могут быть разные. И у нами эволюционно заложены различные режимы работы нашей системы, зависит от ситуации. То есть мы можем сбегать, защищаться, нападать, осуществлять поисковое поведение, и много других режимов работы нашей нервной системы. Вот эффективность этих режимов, она как бы подтверждена эволюцией. То есть животные, которые вот эти эмоциональные поведения проявляют, оно не только у человека есть эмоциональные поведения, как животные, как остальные тоже проявляют. Может у нас как бы оно более цивилизованной формы имеет, но тем не менее, эмоции. ну и в сетях, соответственно, нейронов тоже можно создавать различные режимы поведения, изменяя коэффициенты в различных, то есть не веса связи отдельные, а коэффициенты при законах обучения, аптекоактивации, ну и многих других, и, соответственно, этим менять режим работы, когда ты лучше обучаешься, когда ты на сильнее реагируешь, ну и, в целом, эмоции – это А, собственно, это вот именно режимы и другие работы нервной системы. Ну и вот те модели, которые сейчас существуют эмоционально, они на самом деле, как правило, не эмоциональны, они направлены на манипуляцию человеческими эмоциями, то есть там модель вам улыбается, как говорится, с сахарным голосом с вами говорит. на вас эмоциональное воздействие, но эмоции есть только у вас, а модель имитирует эти эмоции, то есть вопрос имитации интеллекта он сложный, а вот с теми моделями, которые сейчас есть, с этим все достаточно просто. Ну и последние два слайда, что такое сильный искусственный искусственного интеллекта ряд уже серьезных компаний занимается искусственным интеллектом я слежу последний последний слава вот и значит повторюсь что вот норвег рассказал что современные модели это как бы уже есть сильный искусственный интеллект я значит с этим не согласен что осталось чуть-чуть но еще все-таки есть что значит докручивать что действительно Это способность освоения имеющихся и получения принципиально новых, то есть тех, которые не следуют согласно доступным методикам современных знаний, и их используют для постановки новых целей развития цивилизации. Согласно изрозленным представлениям, сильный искусственный И компонент, что я еще не написал, то есть на каждом уровне должны быть много моделей различных компонентов этого сложного мира, которые статистически достоверно могут быть описаны. Аеристическая структура позволяла бы строить модели от текущих ситуаций и на основе имеющихся знаний преобразовывать входные и выходные. ну и что важно, что факт наличия иерархической структуры компонентной, он недостаточен, то есть если там будет десяток компонентов и три уровня иерархии, то собственно это не будет сильным искусственным интеллектом, просто потому что как бы развитие слабовато, то есть это должно быть ну хотя бы 5-6, а лучше 10 уровней, ну и на каждом уровне желательно, чтобы было в общем-то сотня, а лучше тысяча компонентов, вот собственно такого уровня. ну и собственно выводы. первое, это то, что Представление о том, что интуиция у нас в одной области головы, мышление в другой области головы, а сознание в третьей области головы, оно, на мой взгляд, неправильное. Мы не можем копировать наше представление в разные области, тем более по разным исходам. То есть в этой модели, которая рассказывала, все происходит на одних и тех же знаниях, которые реализованы на одних и тех же структурах, просто работает в разных режимах, ну и сознание не то, чтобы оно… те же самые знания используют, там, конечно, есть специфические знания, но она оценивает работу одних и тех же структур. Соответственно, второе, это то, что аппроксимация моделирования основана на выделении на куплевых знаниях простых объектов явлений. Ну просто потому, что сложные объекты явления, ну и специфически не можно исследовать. Соответственно, увеличение... числа простых объектов, которые мы уже знаем и можем моделировать у себя в голове, оно ускоряет процесс получения новых знаний. Именно за счет того, что мы используем эти знания для композиции сложных сцен, и нам это позволяет получать новые знания про те объекты, которые без наличия. и тех знаний, которые у нас есть, мы бы не смогли с такой декомпозицией получить новые объекты знаний. Не важно, что эти знания сперва получаются невербально, то есть мы сейчас, те модели, которые есть, они в значительной степени основаны на невербальных, то есть текстовых знаниях, а в принципе безживотный мир живет без текстовой обработки и прекрасно справляется. ну и человек пока он не стал цивилизованным он тоже прекрасно справлялся вот цивилизация нам конечно очень помогает за счет того что те знания которые мы получаем от цивилизации нам сильно облегчают понимание окружающего мира и собственно быстрее получать новые знания как я говорил Миша но тем не менее сильный искусственный интеллект должен быть способен к выделению невербальных знаний в окружающем мире Ну, значит, необходима декомпозиция, лидеризация, локализация представления знаний и случайных данных. Это как бы более эффективно, чем просто градиентный спуск метода. Хотя градиентный спуск поддерживает все эти данные, как и любую другую оптимизацию, но он непосредственно не направлен. Желательно строить такие модели, которые... Ну и, собственно, языково-семантические знания, они, конечно, полезные, то есть для нас они очень важны, но они вторичны по отношению к моделям пространство-состояния. То есть если у нас эти знания не соответствуют этим непрерывным моделям пространства-состояний, то они являются книжными. Мы можем по ним что-то рассказывать, собственно, хорошую, значит, использовать их в практической деятельности сможем тогда, когда сформируем вот эти непрерывные модели. ну и последнее, я уже раньше сказал, что, собственно, ППГщ не поддерживает любую сложную форму оптимизации, поскольку, как бы мы и не улучшали процесс преобразования он всегда будет поддержан где-то на спуске, но то, о чем я рассказал, направлено на то, что надо строить такие модели, которые по своей идее строения направлен именно на декомпозицию, локализацию и линеризацию, и это, обязательно, ускорит процесс обучения. Вот все, что я хотел рассказать, ну и, конечно, многое, может быть, я и не рассказал, но, наверное, просто время давно закончилось. Я хочу сказать всем спасибо, кто меня слушал и готов ответить на ваши вопросы, есть ли они, есть.
А. КОЛОНИН [01:27:46]  : Владимир, спасибо. Здесь парочка вопросов есть из Телеграма. Допустим, происходит наблюдение в скобках моделирования какого-либо объекта. С пассивным наблюдением вроде пояснили, а вот могли бы Вы чуть подробнее про воздействие на наблюдаемый объект через аффекторы в скобках манипуляторы? Вам не кажется, что эти алгоритмы там устойчивы и однотипны, так как задача инструмента и ее решения определены? Возможно ли рассмотреть на той же кошке? Только теперь её будем щупать или тыкать. Спасибо. Как не гуманно по отношению к кошке, но давайте.
В. СМОЛИН [01:28:31]  : Можно и к кошке, но собственно... Знаете, я говорил о том, что в самом начале... Давайте я попробую туда посмотреть быстренько. Вот, что... Речь шла в основном про постановку целей, что мы, в том числе, когда действуем руками, это тоже объекты, или ногами, или палкой, мономашиной рулем, все равно мы нашими органами чувств, неважно, щупаем мы кошку, смотрим на нее, палкой в нее тыкаем, мы все равно наблюдаем за своими действиями ее реакции, то есть то, о чем к структуре модели свойств объектов и взаимодействия. То есть мы наблюдаем, в том числе за своими собственными действиями, смотрим модели свойств окружающего мира, то есть тело как бы для нашей нервной системы это тоже некоторый объект. Другое дело, что мы за этим объектом можем не только внешними органами чувств наблюдать, а наблюдать и за счет внутренних чувств, то есть насколько напряжены мышцы, холодно, больно, еще какие-то ощущения внутренние, которые к этим органам чувств не относятся. Но в любом случае мы можем в этой части строить модели как внешнего мира, так и своего тела и ставить какие-то цели. Вопрос, как идет управление телом, там есть свои особенности и я сегодня его не касался. Может быть как-нибудь я соберусь и расскажу. Там, конечно, есть свои особенности, но для того, чтобы осуществить это управление, в любом случае надо ставить какие-то цели, и когда уже эти цели поставлены, тогда идёт управление телом. Ну и, опять-таки, не всё мы сознательно контролируем, там много управления идёт без сознательного контроля, но значительная часть, по крайней мере, наших действий, она… Идет на основе тех целей, которые мы на основе построенных нами моделей внешнего мира, как я считаю компонентных моделей, хотя кто-то может с этим не соглашаться, вот они значит для управления телом формируют цели и тело уже в зависимости от того, насколько оно хорошо готово к выполнению этих целей, эти цели реализуют. Повторюсь, я сегодня рассказывал о другом, это как бы отдельная большая интересная тема, я готов там как-то подготовиться рассказать. Так же, как и отдельная тема, это собственно система оценок, поскольку, конечно, мы там, скажем так, эволюционно-генетически не подготовлены, допустим, к общению с фейкбордом изобрели недавно и, соответственно, никак это на нашу генетику не повлияло. Но мы оцениваем, что да, это интересно, хорошо, ну и много там есть цивилизационных особенных вещей, которые явно генетически у нас не заложены, тем не менее мы строим их оценки на основе наших как генетически заложенных низкоуровневых оценок, ну и так наших тех знаний, которые мы получили в цивилизации, и там тоже есть свои особенности. Но, повторюсь, я сегодня тоже рассказывал не об этом. Я сегодня рассказывал вопрос о том, что как сложный мир разбить на компоненты и на основе выявлений и свойств путем наблюдения, поскольку когда мы разбили на компоненты, они становятся статистически достоверно доступны для изучения, тогда мы строим их модели и можем моделировать, как действовать в той ситуации, которую встретил впервые. потому что компоненты находятся в тех состояниях, которые нам известны, мы знаем, что будет, если на них как-то подействовать, и можем промоделировать, если эти модели у нас там уже динамические, то можно промоделировать, а что произойдет при одном, другом, третьем варианте действия. Вот, собственно, о чем я пытался рассказать. А вопрос управления телом и системой оценок – это как бы тема отдельных докладов.
А. КОЛОНИН [01:32:47]  : да извиняюсь вопрос от алексея удоб на каких конкретно задачах вы пробовали и проверяли свои гипотезы и методы и какие конкретно были результаты так что-то опять со звуком
В. СМОЛИН [01:33:12]  : Ну, то есть, модель концептуальная, пока что, к сожалению, она в реальной модели не реализовывается.
А. КОЛОНИН [01:33:32]  : Владимир, тогда от меня пара вопросов еще, что называется, на засыпку. Если нейросеть – это аппроксиматор, то что аппроксимирует ЧАТ ЖПТ? То есть, вот, например, у нас Александр Балдачев показывал, как он ЧАТ ЖПТ научил работать с антологиями, и нейросеть ему как разбирала текст на антологии, так и генерировала антологии по тексту в ту и в другую сторону.
В. СМОЛИН [01:34:03]  : ну скажем так что с моей точки зрения да безусловно то есть нейросети которые есть входной сигнал на основе структуры связи которая заложена ну и скажем так что не только вот эти полнослойные полносвязанные слои а там естественно есть и рекуррентная компонента и во всех значит собственно сам вот этот pretrained transformers то есть генерируется претренинг трансформеров, то есть вот как например Воронцов объясняет в чем смысл трансформеров это в том, что есть различные техники придания вектора различным словам, но, как вы понимаете, если просто слову предать какой-то вектор, то это и плохо в том смысле, что одно и то же слово может иметь различные значения в зависимости от того, в каком оно контексте звучит. И, соответственно, вот этот вот трансформер, как воспринимает и Фаранцов, и я так считаю, что достаточно грамотное это восприятие, что они осуществляют трансформацию вот этого векторного представления слов в зависимости от контекста. Ну и вот эти GPT-3 и GPT-4, они учитывают достаточно широкий текст вокруг, то есть трансформация векторного представления слов идет с учетом достаточно широкого контекста вокруг этого слова, и это позволяет, ну скажем так, аппроксимироваться более разумно, чем если бы мы использовали какое-то уникальное значение этого слова, которое не соответствует контексту.
А. КОЛОНИН [01:35:44]  : Да, извиняюсь, вот и следующий вопрос, то есть, окей, да, понятно, принято, но тогда человеческий мозг – это не аппроксиматор, но тоже же как бы нейроны, весовые функции.
В. СМОЛИН [01:35:55]  : Меня всегда радует, что трансформеры несут какую-то чушь. А человек на основе своих нейросетей, он всегда говорит абсолютно истину. Ну вот, я был бы очень рад познакомиться с таким человеком, который говорит абсолютно истинно, но у меня пока таких людей не встречалось. И более того, собственно, если подумать, то там-то в голове у нас все-таки нейроны, и они тоже работают так же, как эти трансформеры на нейронных сетях. Конечно, они работают на других принципах, я не буду говорить о том, что у нас есть обратное составляние ошибки, это все другое, но мы так же, как мы не понимаем, преобразование в трансформерах, также мы не понимаем, как осуществляется преобразование в нейронных сетях в нашей голове. И то, что мы там про это говорим, что вот ну мне же это очевидно, но вот как там происходит в нейросетях, вот все это говорит, они даже не задумываются. Ну и, соответственно, вот мое-то мнение, что вот происходит примерно так, как я рассказал в этой модели. У каждого, конечно, свои представления, но в любом случае мы прогоняем вот эти данные, которые вступают в сенсоров через наши нейронные сети, и, конечно, какое-то там преобразование есть, и это преобразование можно рассматривать как некоторую аппроксимацию.
А. КОЛОНИН [01:37:10]  : Спасибо. Здесь вот мне еще обратили внимание, что в YouTube были вопросы. Во-первых, там Вадим Шевчук передает вам добрый вечер, и, оказывается, он давно ждал вашего доклада. вот так что да вот и два вопроса есть во первых есть вопрос от пользователей аф-яф к рисунку про кота с ракеткой как определяются границы в скобках свойства ракетки когда границу других объектов в скобках кота фона и т.д. нам неизвестны
В. СМОЛИН [01:37:50]  : Как я говорил, что необходимо вычитать, осуществлять вычитание, но чтобы осуществлять вычитание, необходима вот эта самая нелинейная декомпозиция. То есть мы осуществляем суммирование, то есть чтобы осуществлять нелинейную декомпозицию, нужно осуществить нелинейное суммирование. тех компонентов, которые есть, и вычитать. То есть, конечно, всем легче себе представить, что мы спроецировали изображение на простыню, или даже лучше на фотобумагу, потом ракетку ножницами вырезали, и вот она, собственно, есть. Естественно, в нейросетях, особенно в многоуровневой сети, там не такое представление, то есть речь идет про активность нейронов. в векторном представлении этой модели и когда мы сочетаем эту нелинейную декомпозицию, ну вот только таким путем мы сочетаем. Ну и я пытался сказать, что вот эта вот нелинейная сумма с нейросетями, она достаточно уже хорошо сейчас сочетается. Хотя, повторюсь, это пока что, как сказать, концептуальная модель. Естественно, было бы более убедительно, если бы она действительно работала в живую.
А. КОЛОНИН [01:38:58]  : Спасибо, и следующий вопрос тоже от Яф-Яф, а если на ракетке сидит бабочка, также новый объект, как формируются границы модели ракетки и бабочки?
В. СМОЛИН [01:39:10]  : Ну как я уже говорил, что вариантов два, либо то, что мы выделили новое у нас достаточно простое, либо нет, то есть мы пытаемся построить статистически достоверное описание. Если то, что выделено, простое, то есть если ракетка и бабочка достаточно в сумме простое, что мы можем описать их одновременно, ну, соответственно, мы построим их модель. А если не можем, то нужно будет, соответственно, ждать, пока мы построим модель ракетки без бабочки. И тогда, когда мы не только кошку, но и ракетку вычтем из картины, тогда мы сможем построить модель бабочки.
А. КОЛОНИН [01:39:49]  : Спасибо. Коллеги, еще есть вопросы? Вопросов больше нет, есть комментарий от Елизара Талипова, что моделирование объектов управления не приводит к получению модели управляющего, знающего, познающего. Прокомментируете, Владимир?
В. СМОЛИН [01:40:19]  : Ну, у каждого объекта свои взгляды. Если, значит, у Елизары это не приводит, ну, что же делать? Его не приводят. случайными действиями какого-то действующего объекта, в том числе, допустим, случайные действия, какие-то рукой осуществляем, то все равно эти наблюдения позволят нам построить модель этой руки и соотнести их с теми сигналами, которые мы давали, чтобы поднимать, допустим, руку вверх, влево, вправо, ее двигать. поступает цель поднять руку, и мы знаем, что при таком управлении она пойдет влево, при таком – вправо, при таком – вверх, причем есть какие-то пропорции по уровню подъема, в зависимости от того, насколько сильный у нас сигнал на подъем руки вверх, то требуемой высоты руки можно достичь. То есть наличие модели различных состояний руки с тем управлением, которое у нее поступает, желательно динамические модели. То есть не только статические положения руки, но и динамические движения. Их тоже можно отмоделировать. И, соответственно, если эта модель есть, то можно поставить цель для этой модели, чтобы она прошла через какие-то состояния и пришла к какому-то конечному состоянию. Ну или там осуществила бросок, например, или махнула. В общем, различные могут быть цели поставлены. И, соответственно, если модель есть, то этих целей достаточно просто достичь. А если модели нет, ну, соответственно... будет сложно ну и собственно поскольку человек ну и вообще любое животное он достаточно сложный объект то не все возможные действия значит всеми животными людьми осуществляются то есть если там гимнастам легко осуществляет достаточно сложное управление ну или там йог там ну не делай конечно там еще в растяжке там физические подготовки Но есть там много движений, какие-нибудь танцоры осуществляют движения, не требующие ни физической подготовки, ни растяжки, а просто координации, которые неподготовленные человек не совершит. То есть, хотя возможности есть, но в той области, где действия совершаются, там формируется их хорошая модель, там может быть достаточно тонкое управление. А в тех областях, в которых опыта нет, соответственно, модель не сформирована, там, собственно, и управление плохое.
А. КОЛОНИН [01:42:51]  : Владимир, спасибо, коллеги, еще есть вопросы? Есть комментарий от Сергея Терехова, что большое спасибо Владимиру, но он вынужден убегать.
В. СМОЛИН [01:43:01]  : Ну и ему спасибо, что мне был приятно с ним.
А. КОЛОНИН [01:43:09]  : Хорошо. Если больше вопросов нет, то тогда, Владимир, спасибо вам большое. И всем, коллеги, до новых встреч. Следующая встреча через две недели. На следующей неделе работаем над созданием дружественного AGI. Всем спасибо. Спасибо, Владимир. Спасибо всем участникам. До свидания. 

_https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html_
